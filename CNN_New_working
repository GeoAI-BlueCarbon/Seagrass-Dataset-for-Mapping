import numpy as np
import geopandas as gpd
import rasterio
from shapely.geometry import mapping
from rasterio.mask import mask
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.model_selection import KFold
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.activations import gelu
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint
import os

# === CONFIG ===
BASE_PATH = '/content/drive/MyDrive/Seagrass'
RASTER_PATH = f'{BASE_PATH}/Raster/t2.tif'
SHAPEFILE_PATH = f'{BASE_PATH}/Vector/Samples_4.shp'
CLASS_COLUMN = 'class'
MODEL_DIR = f'{BASE_PATH}'
TIFF_OUTPUT_PATH = f'{BASE_PATH}/Raster/CNN_OP_VAL_5.tif'
PNG_OUTPUT_PATH = f'{BASE_PATH}/CNN_OP_VAL_5.png'
os.makedirs(MODEL_DIR, exist_ok=True)

label_map = {
    'seagrass': 0, 'land': 1, 'mangroves': 2,
    'water': 3, 'othervegetation': 4
}
inv_label_map = {v: k for k, v in label_map.items()}

# === Load Raster and Shapefile ===
raster = rasterio.open(RASTER_PATH)
image = np.transpose(raster.read(), (1, 2, 0))
gdf = gpd.read_file(SHAPEFILE_PATH)

if raster.crs is None:
    raster.crs = gdf.crs
elif gdf.crs != raster.crs:
    gdf = gdf.to_crs(raster.crs)

# === Sample and Extract Features ===
gdf = gdf.sample(n=105, random_state=42)
features, labels = [], []

for _, row in gdf.iterrows():
    geom = [mapping(row.geometry)]
    label = label_map[row[CLASS_COLUMN].lower()]
    try:
        out_image, _ = mask(raster, geom, crop=False)
        out_image = np.transpose(out_image, (1, 2, 0))
        mask_array = out_image.sum(axis=2) > 0
        pixels = out_image[mask_array]
        for pixel in pixels:
            if not np.any(np.isnan(pixel)):
                features.append(pixel)
                labels.append(label)
    except:
        continue

features = np.array(features)
labels = np.array(labels)
print("‚úÖ Features:", features.shape, "Labels:", labels.shape)

# === Preprocess ===
scaler = StandardScaler()
X = scaler.fit_transform(features)
X = X[..., np.newaxis]
y = to_categorical(labels, num_classes=len(label_map))

# === Config ===
kernel_sizes = [3, 5, 7]  # simulate 8, 16, 24 if 2D CNNs
learning_rates = [0.001, 0.005]
epochs = 50
kf = KFold(n_splits=10, shuffle=True, random_state=42)

fold = 1
for k in kernel_sizes:
    for lr in learning_rates:
        print(f"\nüìò Kernel Size: {k}, Learning Rate: {lr}")

        fold_accuracies = []
        best_val_loss = float('inf')

        for train_idx, val_idx in kf.split(X):
            print(f"\nüîÅ Fold {fold}/10")
            X_train, X_val = X[train_idx], X[val_idx]
            y_train, y_val = y[train_idx], y[val_idx]

            model = Sequential([
                Conv1D(64, kernel_size=k, activation='gelu', padding='same', input_shape=(X.shape[1], 1)),
                MaxPooling1D(2),
                Conv1D(32, kernel_size=k, activation='gelu', padding='same'),
                MaxPooling1D(2),
                Flatten(),
                Dense(64, activation='gelu'),
                Dropout(0.3),
                Dense(len(label_map), activation='softmax')
            ])

            model.compile(optimizer=Adam(learning_rate=lr), loss='categorical_crossentropy', metrics=['accuracy'])

            checkpoint_path = f"{MODEL_DIR}/model_k{k}_lr{lr}_fold{fold}.h5"
            checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=1, save_best_only=True)

            history = model.fit(
                X_train, y_train,
                validation_data=(X_val, y_val),
                epochs=epochs,
                batch_size=64,
                callbacks=[checkpoint],
                verbose=0
            )

            val_preds = model.predict(X_val, verbose=0)
            y_true = np.argmax(y_val, axis=1)
            y_pred = np.argmax(val_preds, axis=1)
            acc = accuracy_score(y_true, y_pred)
            fold_accuracies.append(acc)

            val_loss = model.evaluate(X_val, y_val, verbose=0)[0]
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                print(f"‚úÖ Saved better model with loss {val_loss:.4f} at fold {fold}")

            print(f"üìà Fold {fold} Accuracy: {acc:.4f}")
            print(classification_report(y_true, y_pred, target_names=inv_label_map.values()))
            print(confusion_matrix(y_true, y_pred))

            fold += 1

        print(f"\nüîö Summary for kernel={k}, lr={lr}")
        print("Mean Accuracy:", np.mean(fold_accuracies), "¬±", np.std(fold_accuracies))
